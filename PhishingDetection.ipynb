{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phishing Detection using Machine Learning\n",
    "This exercise involves building a phishing detector using two different algorithms:\n",
    "- Logistic Regression\n",
    "- Decision Trees\n",
    "Plus spam detection using Natural Language Processing (NLP).\n",
    "\n",
    "The first part of the exercise will use data from the [UCI Machine Learning Repository (Phishing Websites Data Set)](https://archive.ics.uci.edu/ml/datasets/Phishing+Websites), as converted to CSV for the Machine Learning for Pentesting course (hosted [at this GitHub link](https://raw.githubusercontent.com/PacktPublishing/Mastering-Machine-Learning-for-Penetration-Testing/master/Chapter02/dataset.csv)). Note that the CSV is comprised of 31 columns - vectors with 30 attributes and one result feature.\n",
    "\n",
    "### Part 1: Logistic Regression\n",
    "We will start by using logistic regression to train a predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy and scikit-learn\n",
    "import numpy as np\n",
    "from sklearn import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "training_data = np.genfromtxt('dataset-phishing-detection.csv',delimiter=',',dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1  1  1 ...  1 -1 -1]\n",
      " [ 1  1  1 ...  1  1 -1]\n",
      " [ 1  0  1 ...  0 -1 -1]\n",
      " ...\n",
      " [ 1 -1  1 ...  0  1 -1]\n",
      " [-1 -1  1 ...  1  1 -1]\n",
      " [-1 -1  1 ...  1 -1 -1]]\n",
      "Columns: 31\n"
     ]
    }
   ],
   "source": [
    "# Print the data and number of columns\n",
    "print(training_data)\n",
    "print('Columns: ' + str(len(training_data[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Commentary on the data\n",
    "We can see from the output above that the data consists of an array of arrays containing 31 columns with either -1, 0 or 1. The 31 columns represent 30 features and one result, so we have labelled data. The features are [described in the document accompanying the dataset that can be downloaded here.](https://archive.ics.uci.edu/ml/machine-learning-databases/00327/Phishing%20Websites%20Features.docx) They include things such as whether a website uses an IP address in the address bar or a URL shortener (e.g. tinyurl), features found in HTML and JavaScript on malicious pages (e.g. popups, iframes, redirects) and other indicators of phishing websites. Each indicator either has a binary value (-1 or 1) representing legitimate or phishing or a ternary value (-1, 0 or 1) for legitimate, suspicious and phishing. The final column (the 31st) is the label - a legitimate site is marked -1 whilst a phishing site is 1. \n",
    "\n",
    "Because the data consists of features from -1 to 1, we can use logistic regression if a logistic curve fits the data. However, given the number of features, a decision tree might be more accurate.\n",
    "\n",
    "We might also want to apply dimensionality reduction techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the inputs (attributes) and outputs (results - the last column)\n",
    "inputs = training_data[:,:-1]\n",
    "outputs = training_data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data into training and test data\n",
    "training_inputs = inputs[:2000]\n",
    "training_outputs = outputs[:2000]\n",
    "testing_inputs = inputs[2000:]\n",
    "testing_outputs = outputs[2000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Logistic Regression classifier\n",
    "classifier = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the classifier\n",
    "classifier.fit(training_inputs, training_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = classifier.predict(testing_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Logistic Regression model on test data is: 84.51684152401988\n"
     ]
    }
   ],
   "source": [
    "# Print the accuracy of the model\n",
    "accuracy = 100.0 * accuracy_score(testing_outputs, predictions)\n",
    "print(\"The accuracy of the Logistic Regression model on test data is: \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Decision Trees\n",
    "84.5% accuracy isn't bad, but decision trees might provide better accuracy than logistic regression. We will use sklearn's decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the library\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tree classifier\n",
    "tree_classifier = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "tree_classifier.fit(training_inputs, training_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute some predictions\n",
    "tree_predictions = tree_classifier.predict(testing_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Decision Tree model on testing data is 90.70127001656545\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy and print\n",
    "accuracy = 100 * accuracy_score(testing_outputs, tree_predictions)\n",
    "print(\"The accuracy of the Decision Tree model on testing data is \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion and next steps\n",
    "The next steps in the tutorial involve training an NLP model. After that, I plan to plot the decision boundaries of the models and examine them to pick the next one. Once a model has been suitably trained, it could be used for phishing detection. Basically, it would need to be fed data in the same format as the input. One could potentially scan emails for links and extract the relevant data points about each link. This would, however, require sufficient processing power so would be a task best performed by an email server or similar. Essentially, the idea would be to use this model to make predictions as part of our usual virus and spam scanning - if we find any dodgy links, we can quarantine the email and flag it for review. The result of the review can also provide more labelled data for re-training the model with new data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
